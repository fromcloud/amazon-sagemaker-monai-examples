{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Training using MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "HAM10000(\"Human Against Machine with Machine with 10000 training images\")은 [Harvard Dataverse](https://dataverse.harvard.edu/)에서  \n",
    "호스팅하는 다양한 인구의 피부경 사진 이미지 데이터 세트입니다.  \n",
    "\n",
    "다음과 같은 여러 진단 범주로 구성된 10015개의 이미지로 구성됩니다.  \n",
    "- 광선 각화증 및 상피내 암종/보웬병(akiec) : Actinic keratoses and intraepithelial carcinoma / Bowen's disease\n",
    "- 기저 세포 암종(bcc) : basal cell carcinoma\n",
    "- 양성 각화증 유사 병변(태양 흑점/지루성 각화증 및 편평 태선 (bkl) : benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses)\n",
    "- 피부섬유종(df) : dermatofibroma\n",
    "- 흑색종(mel) : melanoma\n",
    "- 멜라닌세포 모반(nv) : melanocytic nevi\n",
    "- 혈관 병변(vasc) : vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage\n",
    " \n",
    "(Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n",
    "\n",
    "이 예제에서는 Pytorch를 사용하여 [MONAI](http://monai.io) 프레임워크를 Amazon SageMaker에 통합하는 방법을 보여주고 불균형 데이터 세트 및 이미지 변환을 지원할 수 있는  \n",
    "MONAI 사전 처리 변환의 예제 코드를 제공합니다.  \n",
    "또한 이미지 분류를 위해 Densenet과 같은 MONAI 신경망 아키텍처를 호출하는 코드를 보여주고 SageMaker 내에서 모델을 훈련하고 제공하기 위한 Pytorch 코드의 구조를 탐색합니다.  \n",
    "또한 HAM10000 데이터 세트를 사용하여 추론을 위한 모델 교육 및 호스팅 모두를 위한 컴퓨팅 인프라를 시작하고 관리하기 위한 SageMaker API 호출을 다룰 것입니다.  \n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "이 노트북은 100GB의 EBS 및 conda_pytorch_p36 커널이 있는 ml.t2.medium 노트북 인스턴스에서 생성 및 테스트되었습니다.\n",
    "\n",
    "아래 코드는 MONAI 프레임워크와 종속 패키지를 설치하고 환경 변수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "!pip install -r source/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "env_path = Path('.') / 'set.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "skin_cancer_bucket=os.environ.get('SKIN_CANCER_BUCKET')\n",
    "skin_cancer_bucket_path=os.environ.get('SKIN_CANCER_BUCKET_PATH')\n",
    "skin_cancer_files=os.environ.get('SKIN_CANCER_FILES')\n",
    "skin_cancer_files_ext=os.environ.get('SKIN_CANCER_FILES_EXT')\n",
    "base_dir = os.environ.get('BASE_DIR')\n",
    "\n",
    "print('Skin Cancer Bucket: '+skin_cancer_bucket)\n",
    "print('Skin Cancer Bucket Prefix: '+skin_cancer_bucket_path)\n",
    "print('Skin Cancer Files: '+skin_cancer_files)\n",
    "print('Skin Cancer Files Ext: '+skin_cancer_files_ext)\n",
    "print('Base Dir: '+base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM10000 Data Transformation\n",
    "\n",
    "transform_data.ipynb는 dataverse_files.zip을 다운로드하고 메타데이터에서 트레이닝 및 검증 세트를 위한 클래스별로 디렉토리를 빌드하는 변환을 수행합니다.  \n",
    "또한 데이터를 보강하여 트레이닝을 위해 클래스 전체에서 보다 균형 잡힌 데이터 세트를 생성합니다.  \n",
    "스크립트는 변환된 데이터 세트 HAM10000.tar.gz를 모델 트레이닝을 위해 set.env에서 식별된 동일한 S3 버킷에 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run source/transform_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data\n",
    "\n",
    "### 변환된 HAM10000 데이터 세트에 대한 Sagemaker 세션 및 S3 위치 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=base_dir+'HAM10000.tar.gz', bucket=skin_cancer_bucket, key_prefix=skin_cancer_bucket_path)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### Training\n",
    "\n",
    "```monai_skin_cancer.py``` 스크립트는 SageMaker 모델(모델을 로드하는 model_fn 함수)을 트레이닝하고 호스팅하는 데 필요한 모든 코드를 제공합니다.  \n",
    "트레이닝 스크립트는 SageMaker 외부에서 실행할 수 있는 트레이닝 스크립트와 매우 유사하지만 다음과 같은 다양한 환경 변수를 통해 트레이닝 환경에 대한 유용한 속성에 액세스할 수 있습니다.\n",
    "\n",
    "* SM_MODEL_DIR: 모델 아티팩트를 기록할 디렉터리의 경로를 나타내는 문자열입니다. 이러한 아티팩트는 모델 호스팅을 위해 S3에 업로드됩니다..\n",
    "* SM_NUM_GPUS: 현재 컨테이너에서 사용 가능한 GPU 수입니다.\n",
    "* SM_CURRENT_HOST: 컨테이너 네트워크에 있는 현재 컨테이너의 이름입니다.\n",
    "* SM_HOSTS: 모든 호스트를 포함하는 JSON 인코딩 목록 .\n",
    "* SM_CHANNEL_TRAINING: 'training' 채널의 데이터가 포함된 디렉토리 경로를 나타내는 문자열입니다.\n",
    "  \n",
    "학습 환경 변수에 대한 자세한 내용은 다음을 참조하십시오. \n",
    "[SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "일반적인 트레이닝 스크립트는  \n",
    "- 입력 채널에서 데이터를 로드하고, \n",
    "- 하이퍼파라미터로 트레이닝을 구성하고, \n",
    "- 모델을 트레이닝하고, \n",
    "- 나중에 호스팅할 수 있도록 모델을 model_dir에 저장합니다. \n",
    "- 하이퍼파라미터는 스크립트에 인수로 전달되며 argparse.ArgumentParser 인스턴스로 검색할 수 있습니다.\n",
    "\n",
    "MONAI는 UNet, DenseNet, GAN 등과 같은 심층 신경망을 포함하며 대규모 의료 이미지 볼륨에 대한 슬라이딩 윈도우 추론을 제공합니다.  \n",
    "피부암 이미지 분류 모델에서 우리는 손실을 측정하면서 30개의 epochs 동안 피부암 이미지에 대해 MONAI DenseNet 모델을 트레이닝 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize source/monai_skin_cancer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training in SageMaker\n",
    "\n",
    "`PyTorch` 클래스를 사용하면 SageMaker 인프라에서 트레이닝 function을 트레이닝 job으로 실행할 수 있습니다.  \n",
    "트레이닝 스크립트, IAM 역할, 트레이닝 인스턴스 수, 트레이닝 인스턴스 유형 및 하이퍼파라미터를 사용하여 구성해야 합니다.  \n",
    "이 경우 ```ml.p3.8xlarge``` 인스턴스에서 트레이닝 작업을 실행할 것입니다.  \n",
    "그러나 이 예제는 하나 또는 여러 개의 CPU 또는 GPU 인스턴스(([사용가능한 인스턴스의 전체 목록](https://aws.amazon.com/sagemaker/pricing/instance-types/)))에서 실행할 수 있습니다.  \n",
    "hyperparameters 매개변수는 학습 스크립트에 전달될 값의 사전입니다.  \n",
    "위의 ```monai_skin_cancer.py```  스크립트에서 이러한 값에 액세스하는 방법을 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='monai_skin_cancer.py',\n",
    "                    source_dir='source',\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    py_version='py3',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.p3.2xlarge',\n",
    "                    hyperparameters={\n",
    "                        'backend': 'gloo',\n",
    "                        'epochs': 1\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 객체를 구성한 후 S3에 업로드한 HAM10000 데이터 세트를 사용하여 fit할 수 있습니다.  \n",
    "SageMaker는 데이터를 로컬 파일 시스템에 다운로드하므로 트레이닝 스크립트는 디스크에서 데이터를 간단히 읽을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit({'train': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOST Model\n",
    "### Create real-time endpoint\n",
    "\n",
    "트레이닝 작업 이후, PyTorchPredictor를 구축하고 배포하기 위해 ``PyTorch`` estimator 객체를 사용합니다.  \n",
    "그러면 추론을 수행하는 데 사용할 수 있는 Sagemaker 엔드포인트,즉 호스팅 된 예측 서비스가 생성됩니다.\n",
    "\n",
    "위에서 언급했듯이 우리는 필요한 monai_skin_cancer.py 스크립트에 `model_fn`을 구현했습니다.  \n",
    "[sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers)에 정의된  \n",
    "`input_fn`, `predict_fn`, `output_fn` 및 `transform_fm`의 기본 구현을 사용할 것입니다.\n",
    "\n",
    "배포 기능에 대한 arguments를 통해 엔드포인트에 사용할 인스턴스의 수와 유형을 설정할 수 있습니다.  \n",
    "트레이닝 작업에 사용한 값과 같을 필요는 없습니다.  예를 들어 GPU 기반 인스턴스 세트에서 모델을 훈련한 다음 엔드포인트를 CPU 기반 인스턴스에 배포할 수 있지만  \n",
    "모델을 다음과 유사한 CPU 모델로 반환하거나 저장해야 합니다. monai_skin_cancer.py에서는 ```ml.m5.xlarge``` 인스턴스에 모델을 배포합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Images for Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print('Load Test Images for Inference')\n",
    "val_dir = os.path.join(base_dir, 'HAM10000/val_dir')\n",
    "class_names = sorted([x for x in os.listdir(val_dir) if os.path.isdir(os.path.join(val_dir, x))])\n",
    "num_class = len(class_names)\n",
    "image_files = [[os.path.join(val_dir, class_name, x)\n",
    "                for x in os.listdir(os.path.join(val_dir, class_name))[:1]] \n",
    "               for class_name in class_names]\n",
    "image_file_list = []\n",
    "image_label_list = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    image_file_list.extend(image_files[i])\n",
    "    image_label_list.extend([i] * len(image_files[i]))\n",
    "        \n",
    "num_total = len(image_label_list)\n",
    "image_width, image_height = Image.open(image_file_list[0]).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONAI Transform Image using Compose and Skin Cancer Dataset\n",
    "\n",
    "MONAI는 Dictionary 및 Array 형식을 모두 지원하는 변환을 가지고 있으며 의료 이미지의 고차원에 특화되어 있습니다.  \n",
    "변환에는 자르기 및 패드, 강도, IO, 후처리, 공간 및 유틸리티(Crop & Pad, Intensity, IO, Post-processing, Spatial, and Utilities)와 같은 여러 범주가 포함됩니다.  \n",
    "다음 발췌문에서 Compose 클래스는 일련의 이미지 변환을 함께 연결하고 이미지의 단일 텐서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from source.skin_cancer_dataset import SkinCancerDataset\n",
    "from monai.transforms import Compose, LoadPNG, Resize, AsChannelFirst, ScaleIntensity, ToTensor\n",
    "\n",
    "val_transforms = Compose([\n",
    "        LoadPNG(image_only=True),\n",
    "        AsChannelFirst(channel_dim=2),\n",
    "        ScaleIntensity(),\n",
    "        Resize(spatial_size=(64,64)),\n",
    "        ToTensor()\n",
    "])\n",
    "    \n",
    "val_ds = SkinCancerDataset(image_file_list, image_label_list, val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "이제 예측기를 사용하여 실시간 추론을 수행하여 피부암 이미지를 분류할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Sample Inference Results By Class:')\n",
    "\n",
    "for i, val_data in enumerate(val_loader):\n",
    "    response = predictor.predict(val_data[0])\n",
    "    actual_label = val_data[1]\n",
    "    pred = torch.nn.functional.softmax(torch.tensor(response), dim=1)\n",
    "    top_p, top_class = torch.topk(pred, 1)\n",
    "    print('actual class: '+class_names[actual_label.numpy()[0]])\n",
    "    print('predicted class: '+class_names[top_class])\n",
    "    print('predicted class probablity: '+str(round(top_p.item(),2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove endpoint (Optional)\n",
    "예제를 완료한 후 모델을 호스팅하는 인스턴스를 해제하려면 예측 엔드포인트를 삭제하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "sagemaker_run_notebook": {
   "saved_parameters": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
